{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAPÍTULO 6 \n",
    "-\n",
    "Tidy data (dados organizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Introdução  \n",
    "O conceito de Hadley Wickham o define como um conceito que atende os seguintes critérios:  \n",
    " - Cada linha é uma observação (observation)\n",
    " - Cada coluna é uma variável (variable)\n",
    " - Cada tipo de unidade de observação forma uma tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este capítulo descreve diversas formas de como organizar os dados conforme identificadas pelo artigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 Colunas contêm valores, e não variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados podem conter colunas que contêm valores em vez de variáveis. Em geral, é um formato conveniente para a coleta e apresentação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2.1 Mantendo uma coluna fixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao observar esse conjunto de dados podemos ver que nem todas as colunas são variáveis, os valores relacionados à renda estão espalhados em varias colunas.  \n",
    "Esse formato é uma ótima opção para tabelas, mas para analise de dados precisamos reformatar esses dados para que religião, renda e contador sejam variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
      "0                  Agnostic     27       34       60       81       76\n",
      "1                   Atheist     12       27       37       52       35\n",
      "2                  Buddhist     27       21       30       34       33\n",
      "3                  Catholic    418      617      732      670      638\n",
      "4        Don’t know/refused     15       14       15       11       10\n",
      "5          Evangelical Prot    575      869     1064      982      881\n",
      "6                     Hindu      1        9        7        9       11\n",
      "7   Historically Black Prot    228      244      236      238      197\n",
      "8         Jehovah's Witness     20       27       24       24       21\n",
      "9                    Jewish     19       19       25       25       30\n",
      "10            Mainline Prot    289      495      619      655      651\n",
      "11                   Mormon     29       40       48       51       56\n",
      "12                   Muslim      6        7        9       10        9\n",
      "13                 Orthodox     13       17       23       32       32\n",
      "14          Other Christian      9        7       11       13       13\n",
      "15             Other Faiths     20       33       40       46       49\n",
      "16    Other World Religions      5        2        3        4        2\n",
      "17             Unaffiliated    217      299      374      365      341\n"
     ]
    }
   ],
   "source": [
    "pew = pd.read_csv('../../data/pew.csv')\n",
    "\n",
    "print(pew.iloc[:, 0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa vizualização é conhecida como dados \"largos\" (wide). Para transformar dados largos em dados \"longos\" (long) precisamos efetuar uma operação unpivot/melt/gather em nosso dataframe.  \n",
    "O Pandas usa a função melt para reformatar o dataframe de maneira organizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "melt aceita alguns parâmetros: \n",
    " - id_vars: é um contêiner que representa as variáveis que permanecerão inalteradas\n",
    " - value_vars: identifica as colunas que a operação melt será execultada. Por padrão ela será execultada em todas as colunas que não foram especificadas por id_vars\n",
    " - var_name: é uma string para o nome da nova coluna quando melt é execultado em value_vars (var_name é uma coluna que mostra o nome da variavel)\n",
    " - value_name: é uma string para o nome da nova coluna que representa os valores para var_name (value_name é uma coluna com os valores que está contido dentro da variavel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion variable  value\n",
      "0            Agnostic    <$10k     27\n",
      "1             Atheist    <$10k     12\n",
      "2            Buddhist    <$10k     27\n",
      "3            Catholic    <$10k    418\n",
      "4  Don’t know/refused    <$10k     15 \n",
      "\n",
      "                  religion            variable  value\n",
      "175               Orthodox  Don't know/refused     73\n",
      "176        Other Christian  Don't know/refused     18\n",
      "177           Other Faiths  Don't know/refused     71\n",
      "178  Other World Religions  Don't know/refused      8\n",
      "179           Unaffiliated  Don't know/refused    597\n"
     ]
    }
   ],
   "source": [
    "#Não precisamor passar value_vars pois queremos pivotear todas as colunas, exeto a coluna religion\n",
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "\n",
    "print(pew_long.head(), '\\n')\n",
    "print(pew_long.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos alterar os defaults de modo que as colunas sejeitas à operação de melt/unpivot sejam nomeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion income  count\n",
      "0            Agnostic  <$10k     27\n",
      "1             Atheist  <$10k     12\n",
      "2            Buddhist  <$10k     27\n",
      "3            Catholic  <$10k    418\n",
      "4  Don’t know/refused  <$10k     15 \n",
      "\n",
      "                  religion              income  count\n",
      "175               Orthodox  Don't know/refused     73\n",
      "176        Other Christian  Don't know/refused     18\n",
      "177           Other Faiths  Don't know/refused     71\n",
      "178  Other World Religions  Don't know/refused      8\n",
      "179           Unaffiliated  Don't know/refused    597\n"
     ]
    }
   ],
   "source": [
    "pew_long = pd.melt(pew,\n",
    "                   id_vars='religion',\n",
    "                   var_name='income',\n",
    "                   value_name='count')\n",
    "\n",
    "print(pew_long.head(), '\\n')\n",
    "print(pew_long.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2.2 Mantendo várias colunas fixas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nem todo conjunto de dados terá uma coluna que permanecerá inalterada em quanto você execulta um unpivot no restante das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('../../data/billboard.csv')\n",
    "\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo: se quisesse criar uma plotagem de faceta com as classificações semanais, a variável de faceta teria de ser uma coluna do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0 \n",
      "\n",
      "       year            artist                    track  time date.entered  \\\n",
      "24087  2000       Yankee Grey     Another Nine Minutes  3:10   2000-04-29   \n",
      "24088  2000  Yearwood, Trisha          Real Live Woman  3:55   2000-04-01   \n",
      "24089  2000   Ying Yang Twins  Whistle While You Tw...  4:19   2000-03-18   \n",
      "24090  2000     Zombie Nation            Kernkraft 400  3:30   2000-09-02   \n",
      "24091  2000   matchbox twenty                     Bent  4:12   2000-04-29   \n",
      "\n",
      "       week  rating  \n",
      "24087  wk76     NaN  \n",
      "24088  wk76     NaN  \n",
      "24089  wk76     NaN  \n",
      "24090  wk76     NaN  \n",
      "24091  wk76     NaN  \n"
     ]
    }
   ],
   "source": [
    "#fizemos um melt e passamos as colunas que deveriam permanecer inalteradas\n",
    "#depois passamos um nome para a nova variável das semanas e um nome para os valores desta variável\n",
    "billboard_long = pd.melt(\n",
    "    billboard,\n",
    "    id_vars=['year', 'artist',  'track', 'time', 'date.entered'],\n",
    "    var_name='week',\n",
    "    value_name='rating'\n",
    ")\n",
    "\n",
    "print(billboard_long.head(), '\\n')\n",
    "print(billboard_long.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3 Colunas contendo diversas variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As vezes as colunas podem representar diversas variáveis. Esse formato é comunmente visto quando trabalhamos com dados de saúde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
      "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
      "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
      "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
      "       'Deaths_Spain', 'Deaths_Mali'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ebola = pd.read_csv('../../data/country_timeseries.csv')\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Deaths_Guinea  Deaths_Liberia\n",
      "0    1/5/2015  289        2776.0            NaN         1786.0             NaN\n",
      "1    1/4/2015  288        2775.0            NaN         1781.0             NaN\n",
      "2    1/3/2015  287        2769.0         8166.0         1767.0          3496.0\n",
      "3    1/2/2015  286           NaN         8157.0            NaN          3496.0\n",
      "4  12/31/2014  284        2730.0         8115.0         1739.0          3471.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.iloc[:5, [0,1,2,3,10,11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui uma coluna contêm duas variáveis, o status individual e o país. Exemplo: Cases_Guinea e Deaths_Guinea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Day      variable   value\n",
      "0       1/5/2015  289  Cases_Guinea  2776.0\n",
      "1       1/4/2015  288  Cases_Guinea  2775.0\n",
      "2       1/3/2015  287  Cases_Guinea  2769.0\n",
      "3       1/2/2015  286  Cases_Guinea     NaN\n",
      "4     12/31/2014  284  Cases_Guinea  2730.0\n",
      "...          ...  ...           ...     ...\n",
      "1947   3/27/2014    5   Deaths_Mali     NaN\n",
      "1948   3/26/2014    4   Deaths_Mali     NaN\n",
      "1949   3/25/2014    3   Deaths_Mali     NaN\n",
      "1950   3/24/2014    2   Deaths_Mali     NaN\n",
      "1951   3/22/2014    0   Deaths_Mali     NaN\n",
      "\n",
      "[1952 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "ebola_long = pd.melt(ebola, id_vars=['Date', 'Day'])\n",
    "\n",
    "print(ebola_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3.1 Separar e adicionar colunas individualmente (método simples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma coluna pode ser separada com base no underscore (sublinhado), para dividir em duas variáveis. Neste exemplo iremos dívidir uma coluna para o status e uma coluna para o país.  \n",
    "Assim como uma Series e um DataFrame possuem seus próprios métodos, uma String também possui metodos próprios e um deles é o \"split\" que separa uma string com um dado delimitador. Esse delimitador por padrão é um espaço, mas podemos alterar ele, neste caso o delimitador é um underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [Cases, Guinea]\n",
      "1       [Cases, Guinea]\n",
      "2       [Cases, Guinea]\n",
      "3       [Cases, Guinea]\n",
      "4       [Cases, Guinea]\n",
      "             ...       \n",
      "1947     [Deaths, Mali]\n",
      "1948     [Deaths, Mali]\n",
      "1949     [Deaths, Mali]\n",
      "1950     [Deaths, Mali]\n",
      "1951     [Deaths, Mali]\n",
      "Name: variable, Length: 1952, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#obtém a coluna variable, acessa os métodos de string e separa com base em um delimitador\n",
    "variable_split = ebola_long.variable.str.split('_')\n",
    "\n",
    "print(variable_split.iloc[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois da separação os valores são devolvidos em uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(variable_split))\n",
    "\n",
    "print(type(variable_split[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que a coluna foi separa em várias parte, precisamos atribuir essas parte a uma nova coluna.  \n",
    "Porém porecisamos separar os elementos de indicie 0 e 1, ou seja separar o status do contry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Cases\n",
      "1        Cases\n",
      "2        Cases\n",
      "3        Cases\n",
      "4        Cases\n",
      "         ...  \n",
      "1947    Deaths\n",
      "1948    Deaths\n",
      "1949    Deaths\n",
      "1950    Deaths\n",
      "1951    Deaths\n",
      "Name: variable, Length: 1952, dtype: object \n",
      "\n",
      "0       Guinea\n",
      "1       Guinea\n",
      "2       Guinea\n",
      "3       Guinea\n",
      "4       Guinea\n",
      "         ...  \n",
      "1947      Mali\n",
      "1948      Mali\n",
      "1949      Mali\n",
      "1950      Mali\n",
      "1951      Mali\n",
      "Name: variable, Length: 1952, dtype: object\n"
     ]
    }
   ],
   "source": [
    "status_values = variable_split.str.get(0)\n",
    "contry_values = variable_split.str.get(1)\n",
    "\n",
    "print(status_values, '\\n')\n",
    "print(contry_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ebola_long['status'] = status_values\n",
    "ebola_long['contry'] = contry_values\n",
    "\"\"\"\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3.2 Separar e combinar em um único passo (método simples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já que o vetor é devolvido na mesma ordem que nossos dados podemos concatenar o novo vetor aos dados originais ao invés de criar colunas e depois adicionar os dados separadamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Day      variable   value  status country\n",
      "0       1/5/2015  289  Cases_Guinea  2776.0   Cases  Guinea\n",
      "1       1/4/2015  288  Cases_Guinea  2775.0   Cases  Guinea\n",
      "2       1/3/2015  287  Cases_Guinea  2769.0   Cases  Guinea\n",
      "3       1/2/2015  286  Cases_Guinea     NaN   Cases  Guinea\n",
      "4     12/31/2014  284  Cases_Guinea  2730.0   Cases  Guinea\n",
      "...          ...  ...           ...     ...     ...     ...\n",
      "1947   3/27/2014    5   Deaths_Mali     NaN  Deaths    Mali\n",
      "1948   3/26/2014    4   Deaths_Mali     NaN  Deaths    Mali\n",
      "1949   3/25/2014    3   Deaths_Mali     NaN  Deaths    Mali\n",
      "1950   3/24/2014    2   Deaths_Mali     NaN  Deaths    Mali\n",
      "1951   3/22/2014    0   Deaths_Mali     NaN  Deaths    Mali\n",
      "\n",
      "[1952 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#o parâmetro \"expand=True\" faz com que retorne um DataFrame, já ele False (o padrão) devolve uma series de listas\n",
    "variable_split = ebola_long.variable.str.split('_', expand=True)\n",
    "variable_split.columns = ['status','country']\n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1)\n",
    "\n",
    "print(ebola_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3.3 Separar e combinar em um único passo (método mais complicado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aproveitando do fato que o resultado da separação devolve uma lista com dois elementos em que cada elemnteo é uma nova coluna, podemos combinar a lista de itens separados com a função zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pi', '3.14'), ('e', '2.718')]\n"
     ]
    }
   ],
   "source": [
    "constants = ['pi', 'e']\n",
    "values = ['3.14', '2.718']\n",
    "\n",
    "#temos que chamar list na função zip para exibir o conteúdo do objeto zip;\n",
    "#em python 3 zip devolve um iterador\n",
    "print(list(zip(constants, values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma de vizualizar o que zip faz é tomar cada contêiner passado para si e empilha-los uns sobre os outros (como se fosse uma concatenação por linha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar o ebola_long.variable.str.split(' ') para separar os valores da coluna. Porém  o resultado já é um contêiner, e precisamos  \n",
    "descompactá-lo para obter o seu conteúdo (cada lista status-país)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em python o oprador asterisco é usado para desempacotar contêineres. Quando executamos zip nos contêineres desempacotados  \n",
    "o efeito é o mesmo obtido quando criamos valores de status país separadamente anteriormente.  \n",
    "Depois, podemos então atribuir os vetores as colunas simultaneamente usando atribuição múltipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Day      variable   value  status country\n",
      "0       1/5/2015  289  Cases_Guinea  2776.0   Cases  Guinea\n",
      "1       1/4/2015  288  Cases_Guinea  2775.0   Cases  Guinea\n",
      "2       1/3/2015  287  Cases_Guinea  2769.0   Cases  Guinea\n",
      "3       1/2/2015  286  Cases_Guinea     NaN   Cases  Guinea\n",
      "4     12/31/2014  284  Cases_Guinea  2730.0   Cases  Guinea\n",
      "...          ...  ...           ...     ...     ...     ...\n",
      "1947   3/27/2014    5   Deaths_Mali     NaN  Deaths    Mali\n",
      "1948   3/26/2014    4   Deaths_Mali     NaN  Deaths    Mali\n",
      "1949   3/25/2014    3   Deaths_Mali     NaN  Deaths    Mali\n",
      "1950   3/24/2014    2   Deaths_Mali     NaN  Deaths    Mali\n",
      "1951   3/22/2014    0   Deaths_Mali     NaN  Deaths    Mali\n",
      "\n",
      "[1952 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "ebola_long['status'], ebola_long['country'] = zip(*ebola_long.variable.str.split('_'))\n",
    "\n",
    "print(ebola_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4 Variáveis tanto em linhas quanto em colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta subseção ira mostrar como organizar os dados caso hajá duas variáveis em uma única e coluna, e varias colunas para uma única variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  d7\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN NaN\n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN NaN\n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN NaN\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv('../../data/weather.csv')\n",
    "\n",
    "print(weather.iloc[:5, :11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso a coluna element possuí duas variáveis que precisam ser submetidas a cast/pivot para separar as variáveis de tmax e tmin (temperatura máxima e mínima).  \n",
    "Já as variáveis de dias precisam ser submetidas a um melt, para transformar em uma única coluna com os dias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos execultar a operação de melt nos dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  year  month element  day  temp\n",
      "0    MX17004  2010      1    tmax   d1   NaN\n",
      "1    MX17004  2010      1    tmin   d1   NaN\n",
      "2    MX17004  2010      2    tmax   d1   NaN\n",
      "3    MX17004  2010      2    tmin   d1   NaN\n",
      "4    MX17004  2010      3    tmax   d1   NaN\n",
      "..       ...   ...    ...     ...  ...   ...\n",
      "677  MX17004  2010     10    tmin  d31   NaN\n",
      "678  MX17004  2010     11    tmax  d31   NaN\n",
      "679  MX17004  2010     11    tmin  d31   NaN\n",
      "680  MX17004  2010     12    tmax  d31   NaN\n",
      "681  MX17004  2010     12    tmin  d31   NaN\n",
      "\n",
      "[682 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "weather_melt = pd.melt(weather,\n",
    "                       id_vars=['id','year','month','element'],\n",
    "                       var_name='day',\n",
    "                       value_name='temp')\n",
    "\n",
    "print(weather_melt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight foda que tive agora\n",
    "-\n",
    "\n",
    "    -melt = transforma as colunas em valores dentro de uma só coluna\n",
    "    \n",
    "    -pivot = transforma valores dentro de uma coluna em uma coluna única"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos pivotear as variáveis armazenadas na coluna element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1  d30  27.8  14.5\n",
      "1        MX17004  2010      2  d11  29.7  13.4\n",
      "2        MX17004  2010      2   d2  27.3  14.4\n",
      "3        MX17004  2010      2  d23  29.9  10.7\n",
      "4        MX17004  2010      2   d3  24.1  14.4\n",
      "5        MX17004  2010      3  d10  34.5  16.8\n",
      "6        MX17004  2010      3  d16  31.1  17.6\n",
      "7        MX17004  2010      3   d5  32.1  14.2\n",
      "8        MX17004  2010      4  d27  36.3  16.7\n",
      "9        MX17004  2010      5  d27  33.2  18.2\n",
      "10       MX17004  2010      6  d17  28.0  17.5\n",
      "11       MX17004  2010      6  d29  30.1  18.0\n",
      "12       MX17004  2010      7   d3  28.6  17.5\n",
      "13       MX17004  2010      7  d14  29.9  16.5\n",
      "14       MX17004  2010      8  d23  26.4  15.0\n",
      "15       MX17004  2010      8   d5  29.6  15.8\n",
      "16       MX17004  2010      8  d29  28.0  15.3\n",
      "17       MX17004  2010      8  d13  29.8  16.5\n",
      "18       MX17004  2010      8  d25  29.7  15.6\n",
      "19       MX17004  2010      8  d31  25.4  15.4\n",
      "20       MX17004  2010      8   d8  29.0  17.3\n",
      "21       MX17004  2010     10   d5  27.0  14.0\n",
      "22       MX17004  2010     10  d14  29.5  13.0\n",
      "23       MX17004  2010     10  d15  28.7  10.5\n",
      "24       MX17004  2010     10  d28  31.2  15.0\n",
      "25       MX17004  2010     10   d7  28.1  12.9\n",
      "26       MX17004  2010     11   d2  31.3  16.3\n",
      "27       MX17004  2010     11   d5  26.3   7.9\n",
      "28       MX17004  2010     11  d27  27.7  14.2\n",
      "29       MX17004  2010     11  d26  28.1  12.1\n",
      "30       MX17004  2010     11   d4  27.2  12.0\n",
      "31       MX17004  2010     12   d1  29.9  13.8\n",
      "32       MX17004  2010     12   d6  27.8  10.5\n"
     ]
    }
   ],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id', 'year', 'month', 'day'],\n",
    "    columns='element',\n",
    "    values='temp'\n",
    ")\n",
    "weather_tidy_flat = weather_tidy.reset_index()\n",
    "\n",
    "print(weather_tidy_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do mesmo modo também podemos aplicar esses métodos sem o dataframe intermediário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1  d30  27.8  14.5\n",
      "1        MX17004  2010      2  d11  29.7  13.4\n",
      "2        MX17004  2010      2   d2  27.3  14.4\n",
      "3        MX17004  2010      2  d23  29.9  10.7\n",
      "4        MX17004  2010      2   d3  24.1  14.4\n",
      "5        MX17004  2010      3  d10  34.5  16.8\n",
      "6        MX17004  2010      3  d16  31.1  17.6\n",
      "7        MX17004  2010      3   d5  32.1  14.2\n",
      "8        MX17004  2010      4  d27  36.3  16.7\n",
      "9        MX17004  2010      5  d27  33.2  18.2\n",
      "10       MX17004  2010      6  d17  28.0  17.5\n",
      "11       MX17004  2010      6  d29  30.1  18.0\n",
      "12       MX17004  2010      7   d3  28.6  17.5\n",
      "13       MX17004  2010      7  d14  29.9  16.5\n",
      "14       MX17004  2010      8  d23  26.4  15.0\n",
      "15       MX17004  2010      8   d5  29.6  15.8\n",
      "16       MX17004  2010      8  d29  28.0  15.3\n",
      "17       MX17004  2010      8  d13  29.8  16.5\n",
      "18       MX17004  2010      8  d25  29.7  15.6\n",
      "19       MX17004  2010      8  d31  25.4  15.4\n",
      "20       MX17004  2010      8   d8  29.0  17.3\n",
      "21       MX17004  2010     10   d5  27.0  14.0\n",
      "22       MX17004  2010     10  d14  29.5  13.0\n",
      "23       MX17004  2010     10  d15  28.7  10.5\n",
      "24       MX17004  2010     10  d28  31.2  15.0\n",
      "25       MX17004  2010     10   d7  28.1  12.9\n",
      "26       MX17004  2010     11   d2  31.3  16.3\n",
      "27       MX17004  2010     11   d5  26.3   7.9\n",
      "28       MX17004  2010     11  d27  27.7  14.2\n",
      "29       MX17004  2010     11  d26  28.1  12.1\n",
      "30       MX17004  2010     11   d4  27.2  12.0\n",
      "31       MX17004  2010     12   d1  29.9  13.8\n",
      "32       MX17004  2010     12   d6  27.8  10.5\n"
     ]
    }
   ],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id','year','month','day'],\n",
    "    columns='element',\n",
    "    values='temp')\\\n",
    "        .reset_index()\n",
    "\n",
    "print(weather_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.5 Várias unidades de observação em uma tabela (normalização)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfe_certo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
